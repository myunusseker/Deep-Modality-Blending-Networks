{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Add,Multiply,Softmax,Input,TimeDistributed,Dense,Average,GlobalAveragePooling1D,Concatenate,Lambda,RepeatVector, Conv2D,ConvLSTM2D, MaxPooling2D,BatchNormalization,Flatten,Reshape,UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.display import display as html_width\n",
    "html_width(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_max = 5\n",
    "train_N = 40\n",
    "train_p = np.random.permutation(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Modality Blending Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_sample(action_type = -1, coef = -1):\n",
    "    n = np.random.randint(0,obs_max)+1\n",
    "    d = train_p[np.random.randint(0, train_N)]\n",
    "    if action_type == -1:\n",
    "        action_type = np.random.randint(0,2)\n",
    "        action_type=0\n",
    "        if action_type == 0:\n",
    "            action_type = 'move'\n",
    "        else:\n",
    "            action_type = 'grasp'\n",
    "    if coef == -1:\n",
    "        coef = np.random.rand()\n",
    "    img_coef = np.ones((1,128)) * coef\n",
    "    pose_coef = np.ones((1,128)) * (1-coef)\n",
    "    observation = np.zeros((1,n,128,128,4)) \n",
    "    observation_pose = np.zeros((1,n,8)) \n",
    "    target_X = np.zeros((1,1))\n",
    "    target_Y = np.zeros((1,128,128,6))\n",
    "    target_Y_pose = np.zeros((1,14))\n",
    "    pose = np.loadtxt('../data/data2020/%d/%s/joint_%d.txt'%(d,action_type,d))\n",
    "    pose[:,-1] *= 10\n",
    "    time_len = pose.shape[0]\n",
    "    times = np.linspace(0,1,time_len)\n",
    "    perm = np.random.permutation(time_len)\n",
    "    for i in range(n):\n",
    "        observation[0,i,:,:,0] = np.ones((128,128))*times[perm[i]]\n",
    "        observation[0,i,:,:,1:] = mpimg.imread('../data/data2020/%d/%s/%d.jpeg'%(d,action_type,perm[i]))/255.\n",
    "        observation_pose[0,i,0] = times[perm[i]]\n",
    "        observation_pose[0,i,1:] = pose[perm[i]]\n",
    "    target_X[0,0] = times[perm[n]]\n",
    "    target_Y[0,:,:,:3] = mpimg.imread('../data/data2020/%d/%s/%d.jpeg'%(d,action_type,perm[n]))/255.\n",
    "    target_Y_pose[0,:7] = pose[perm[n]]\n",
    "    return [observation, observation_pose, target_X, img_coef, pose_coef], [target_Y, target_Y_pose], d, perm[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_predicted):\n",
    "    mean, log_sigma = tf.split(y_predicted, 2, axis=-1)\n",
    "    y_true_value, temp =tf.split(y_true,2,axis=-1)\n",
    "    sigma = tf.nn.softplus(log_sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalDiag(loc=mean, scale_diag=sigma)\n",
    "    loss = -tf.reduce_mean(dist.log_prob(y_true_value))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_layer = Input(shape=(None,128,128,4), name=\"image_observation\") \n",
    "joint_layer = Input(shape=(None,8), name=\"joint_observation\") \n",
    "target_X_layer = Input(shape=(1,), name = 'target_X')\n",
    "img_coef_layer = Input(shape=(128,), name = 'image_coef')\n",
    "pose_coef_layer = Input(shape=(128,), name = 'pose_coef')\n",
    "\n",
    "encoder_joint_sizes = [64,64,128,128,256]\n",
    "\n",
    "joint_encoder = TimeDistributed(Dense(32, activation = 'relu'))(joint_layer)\n",
    "for channel_size in encoder_joint_sizes:\n",
    "    joint_encoder = TimeDistributed(Dense(channel_size, activation = 'relu'))(joint_encoder)\n",
    "\n",
    "joint_representations = TimeDistributed(Dense(128, activation='relu'))(joint_encoder) #128\n",
    "joint_representation = GlobalAveragePooling1D()(joint_representations) \n",
    "\n",
    "multiplied_joint = Multiply()([joint_representation,pose_coef_layer])\n",
    "\n",
    "###################################################\n",
    "\n",
    "encoder_img_sizes = [64,64,128,128,256]\n",
    "\n",
    "image_encoder = TimeDistributed(Conv2D(32,(3,3),padding='same',activation='relu'))(image_layer)\n",
    "image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "for channel_size in encoder_img_sizes:\n",
    "    image_encoder = TimeDistributed(Conv2D(channel_size,(3,3),padding='same',activation='relu'))(image_encoder)\n",
    "    image_encoder = TimeDistributed(MaxPooling2D((2,2)))(image_encoder)\n",
    "\n",
    "image_flatten = TimeDistributed(Flatten())(image_encoder)\n",
    "img_representations = TimeDistributed(Dense(128, activation='relu'))(image_flatten)\n",
    "img_representation = GlobalAveragePooling1D()(img_representations) \n",
    "\n",
    "multiplied_img = Multiply()([img_representation,img_coef_layer])\n",
    "\n",
    "general_representation = Add()([multiplied_joint,multiplied_img])\n",
    "\n",
    "merged_layer = Concatenate(axis=-1, name='merged')([general_representation,target_X_layer])\n",
    "\n",
    "####################################################\n",
    "\n",
    "decoder_representation = Dense(1024, activation='relu') (merged_layer)\n",
    "\n",
    "\" =============== Image Decoder =============== \"\n",
    "decoder_img = Reshape([2,2,256])(decoder_representation)\n",
    "decoder_img_sizes = [256,128,128,64,64,32]\n",
    "\n",
    "for channel_size in decoder_img_sizes:\n",
    "    decoder_img = Conv2D(channel_size, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "    decoder_img = UpSampling2D((2, 2))(decoder_img)\n",
    "\n",
    "img_output = Conv2D(16, (3,3), padding='same', activation='relu')(decoder_img)\n",
    "img_output = Conv2D(8, (3,3), padding='same', activation='relu')(img_output)\n",
    "img_output = Conv2D(6, (3,3), padding='same', activation='sigmoid')(img_output)\n",
    "\" =============== Image Decoder =============== \"\n",
    "\n",
    "\" =============== Joint Decoder =============== \"\n",
    "decoder_joint = Dense(512, activation='relu')(decoder_representation)\n",
    "decoder_joint = Dense(216, activation='relu')(decoder_joint)\n",
    "decoder_joint = Dense(128, activation='relu')(decoder_joint)\n",
    "decoder_joint = Dense(32, activation='relu')(decoder_joint)\n",
    "joint_output = Dense(14)(decoder_joint)\n",
    "\" =============== Joint Decoder =============== \"\n",
    "model = Model([image_layer, joint_layer, target_X_layer, img_coef_layer, pose_coef_layer],[img_output,joint_output])\n",
    "latent_model = Model([image_layer, joint_layer, target_X_layer, img_coef_layer, pose_coef_layer],general_representation)\n",
    "model.compile(optimizer = Adam(lr = 1e-4),loss=custom_loss, loss_weights=[1,0.01])\n",
    "model.summary()\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_checkpoint = 1000\n",
    "plot_checkpoint = 1000\n",
    "validation_checkpoint = 1000\n",
    "validation_error = 9999999\n",
    "validation_step = -1\n",
    "max_training_step = 1000000\n",
    "\n",
    "dataset = ['image','joint']\n",
    "\n",
    "float_formatter = \"{:.4f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "for step in range(max_training_step):\n",
    "    inp, out, _, _ = get_train_sample()\n",
    "    callback = model.fit(inp,out)\n",
    "    '''\n",
    "    if step % validation_checkpoint == 0:\n",
    "        pass\n",
    "    '''\n",
    "    if step % plot_checkpoint == 0:\n",
    "        #clearing output cell\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        print(step)\n",
    "        #plotting on-train examples by user given observations\n",
    "        inp, out, d_id, target_t = get_train_sample()\n",
    "        plt.imshow(out[0][0,:,:,:3])\n",
    "        plt.show()\n",
    "        plt.imshow(model.predict(inp)[0][0,:,:,:3])\n",
    "        plt.show()\n",
    "        print(out[1][0,:7])\n",
    "        print(model.predict(inp)[1][0,:7])\n",
    "\n",
    "        inp, out, d_id, target_t = get_train_sample()\n",
    "        plt.imshow(out[0][0,:,:,:3])\n",
    "        plt.show()\n",
    "        plt.imshow(model.predict(inp)[0][0,:,:,:3])\n",
    "        plt.show()\n",
    "        print(out[1][0,:7])\n",
    "        print(model.predict(inp)[1][0,:7])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
